import streamlit as st
import tempfile
import os
import requests
import json
from typing import List, Dict, Any
from dotenv import load_dotenv

# LangChain imports
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.schema import Document

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="PaperPal - AIè®ºæ–‡åŠ©æ‰‹",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

class DoubaoAPI:
    """ç«å±±å¼•æ“è±†åŒ…APIå°è£…ç±»"""
    
    def __init__(self, api_key: str, endpoint_id: str):
        self.api_key = api_key
        self.endpoint_id = endpoint_id
        # ä½¿ç”¨æ­£ç¡®çš„ç«å±±æ–¹èˆŸAPIåœ°å€
        self.base_url = "https://ark.cn-beijing.volces.com/api/v3"
    
    def chat_completion(self, messages: List[Dict[str, str]], temperature: float = 0.7) -> str:
        """è°ƒç”¨è±†åŒ…APIè¿›è¡Œå¯¹è¯"""
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }
            
            data = {
                "model": self.endpoint_id,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": 2000,
                "stream": False
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=30  # å‡å°‘è¶…æ—¶æ—¶é—´
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["choices"][0]["message"]["content"]
            else:
                error_msg = f"è±†åŒ…APIè°ƒç”¨å¤±è´¥ ({response.status_code}): {response.text}"
                st.error(error_msg)
                return f"æŠ±æ­‰ï¼ŒAPIè°ƒç”¨å¤±è´¥ã€‚é”™è¯¯ä¿¡æ¯: {error_msg}"
                
        except Exception as e:
            error_msg = f"è±†åŒ…APIè°ƒç”¨å‡ºé”™: {str(e)}"
            st.error(error_msg)
            return f"æŠ±æ­‰ï¼ŒAPIè°ƒç”¨å‡ºé”™: {error_msg}"

class QwenAPI:
    """é˜¿é‡Œäº‘é€šä¹‰åƒé—®APIå°è£…ç±»"""
    
    def __init__(self, api_key: str, base_url: str = "https://dashscope.aliyuncs.com/api/v1"):
        self.api_key = api_key
        self.base_url = base_url
    
    def chat_completion(self, messages: List[Dict[str, str]], temperature: float = 0.7) -> str:
        """è°ƒç”¨Qwen APIè¿›è¡Œå¯¹è¯"""
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}",
                "X-DashScope-SSE": "disable"
            }
            
            data = {
                "model": "qwen-turbo",
                "input": {
                    "messages": messages
                },
                "parameters": {
                    "temperature": temperature,
                    "max_tokens": 2000,
                    "top_p": 0.8
                }
            }
            
            response = requests.post(
                f"{self.base_url}/services/aigc/text-generation/generation",
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result["output"]["text"]
            else:
                error_msg = f"Qwen APIè°ƒç”¨å¤±è´¥ ({response.status_code}): {response.text}"
                st.error(error_msg)
                return f"æŠ±æ­‰ï¼ŒAPIè°ƒç”¨å¤±è´¥ã€‚é”™è¯¯ä¿¡æ¯: {error_msg}"
                
        except Exception as e:
            error_msg = f"Qwen APIè°ƒç”¨å‡ºé”™: {str(e)}"
            st.error(error_msg)
            return f"æŠ±æ­‰ï¼ŒAPIè°ƒç”¨å‡ºé”™: {error_msg}"

class DoubaoEmbeddings:
    """ç«å±±å¼•æ“è±†åŒ…Embeddingså°è£…ç±»"""
    
    def __init__(self, access_key: str, secret_key: str):
        self.access_key = access_key
        self.secret_key = secret_key
        self.base_url = "https://ark.cn-beijing.volces.com/api/v3"
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡åµŒå…¥æ–‡æ¡£"""
        embeddings = []
        for text in texts:
            embedding = self.embed_query(text)
            embeddings.append(embedding)
        return embeddings
    
    def embed_query(self, text: str) -> List[float]:
        """åµŒå…¥å•ä¸ªæŸ¥è¯¢"""
        try:
            # ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…éœ€è¦è°ƒç”¨ç«å±±å¼•æ“çš„embedding API
            # è¿™é‡Œè¿”å›ä¸€ä¸ªå‡çš„å‘é‡ä½œä¸ºæ¼”ç¤º
            return [0.1] * 1536  # OpenAI embeddingç»´åº¦
        except Exception as e:
            st.error(f"åµŒå…¥ç”Ÿæˆå¤±è´¥: {str(e)}")
            return [0.0] * 1536

@st.cache_resource
def load_pdf_and_create_qa_chain(uploaded_file, api_choice: str):
    """
    åŠ è½½PDFæ–‡ä»¶å¹¶åˆ›å»ºé—®ç­”é“¾
    ä½¿ç”¨Streamlitç¼“å­˜é¿å…é‡å¤å¤„ç†
    """
    try:
        # å°†ä¸Šä¼ çš„æ–‡ä»¶ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        # åŠ è½½PDF
        loader = PyPDFLoader(tmp_file_path)
        documents = loader.load()
        
        # æ–‡æœ¬åˆ†å‰²
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )
        texts = text_splitter.split_documents(documents)
        
        # æ ¹æ®APIé€‰æ‹©é…ç½®åµŒå…¥å’ŒLLM
        if api_choice == "doubao":
            # ä½¿ç”¨è±†åŒ…API
            api_key = os.getenv("DOUBAO_API_KEY")
            endpoint_id = os.getenv("DOUBAO_ENDPOINT_ID")
            
            if not api_key or not endpoint_id:
                st.error("è¯·é…ç½®ç«å±±å¼•æ“è±†åŒ…APIå¯†é’¥ï¼")
                return None
            
            # åˆ›å»ºåµŒå…¥ï¼ˆå…ˆç”¨OpenAIçš„ä½œä¸ºå¤‡é€‰ï¼‰
            openai_key = os.getenv("OPENAI_API_KEY")
            if openai_key:
                embeddings = OpenAIEmbeddings(api_key=openai_key)
            else:
                st.error("è±†åŒ…æ¨¡å¼ä¸‹éœ€è¦é…ç½®OpenAI API Keyç”¨äºæ–‡æ¡£åµŒå…¥")
                return None
            
            # åˆ›å»ºå‘é‡å­˜å‚¨
            vectorstore = Chroma.from_documents(texts, embeddings)
            
            # åˆ›å»ºè‡ªå®šä¹‰çš„è±†åŒ…LLM wrapper
            class DoubaoLLM:
                def __init__(self, doubao_api):
                    self.doubao_api = doubao_api
                
                def __call__(self, prompt: str) -> str:
                    messages = [{"role": "user", "content": prompt}]
                    return self.doubao_api.chat_completion(messages)
            
            doubao_api = DoubaoAPI(api_key, endpoint_id)
            llm = DoubaoLLM(doubao_api)
            
            # åˆ›å»ºé—®ç­”é“¾ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
            
            def qa_chain(question: str) -> str:
                docs = retriever.get_relevant_documents(question)
                context = "\n\n".join([doc.page_content for doc in docs])
                
                prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚

æ–‡æ¡£å†…å®¹ï¼š
{context}

é—®é¢˜ï¼š{question}

è¯·æ ¹æ®æ–‡æ¡£å†…å®¹æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜ã€‚"""
                
                return llm(prompt)
            
            return qa_chain
            
        else:
            # ä½¿ç”¨OpenAI API
            openai_api_key = os.getenv("OPENAI_API_KEY")
            if not openai_api_key:
                st.error("è¯·é…ç½®OpenAI APIå¯†é’¥ï¼")
                return None
            
            # åˆ›å»ºåµŒå…¥
            embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
            
            # åˆ›å»ºå‘é‡å­˜å‚¨
            vectorstore = Chroma.from_documents(texts, embeddings)
            
            # åˆ›å»ºLLM
            llm = ChatOpenAI(
                temperature=0.7,
                model="gpt-3.5-turbo",
                openai_api_key=openai_api_key
            )
            
            # åˆ›å»ºé—®ç­”é“¾
            qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
                return_source_documents=False
            )
            
            return qa_chain
    
    except Exception as e:
        st.error(f"å¤„ç†PDFæ—¶å‡ºé”™: {str(e)}")
        return None
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if 'tmp_file_path' in locals():
            try:
                os.unlink(tmp_file_path)
            except:
                pass

def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    
    # ä¾§è¾¹æ é…ç½®
    # æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .subtitle {
        font-size: 1.2rem;
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .success-box {
        background: linear-gradient(135deg, #a8e6cf 0%, #dcedc1 100%);
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #4CAF50;
        margin: 1rem 0;
    }
    .info-box {
        background: linear-gradient(135deg, #a8cfe6 0%, #c1dced 100%);
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #2196F3;
        margin: 1rem 0;
    }
    .sidebar-logo {
        text-align: center;
        padding: 1rem 0;
        background: rgba(102, 126, 234, 0.1);
        border: 1px solid rgba(102, 126, 234, 0.2);
        border-radius: 12px;
        margin-bottom: 1rem;
        color: #667eea;
        font-weight: bold;
        font-size: 1.3rem;
    }
    .feature-card {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
        border-left: 4px solid #4CAF50;
    }
    .metric-card {
        background: linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%);
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin: 0.5rem;
    }
    .chat-container {
        background: #f8f9fa;
        border-radius: 15px;
        padding: 1rem;
        margin: 1rem 0;
    }
    </style>
    """, unsafe_allow_html=True)

    with st.sidebar:
        # è‡ªå®šä¹‰Logo
        st.markdown("""
        <div class="sidebar-logo">
            <svg width="60" height="60" viewBox="0 0 100 100" style="margin-bottom: 10px;">
                <!-- ä¹¦æœ¬å›¾æ ‡ -->
                <rect x="20" y="25" width="60" height="50" rx="5" fill="#667eea" stroke="#667eea" stroke-width="1" opacity="0.8"/>
                <rect x="25" y="30" width="50" height="40" rx="3" fill="rgba(255,255,255,0.9)"/>
                <!-- AIå¤§è„‘å›¾æ ‡ -->
                <circle cx="50" cy="50" r="12" fill="#667eea" opacity="0.7"/>
                <circle cx="47" cy="47" r="2" fill="white"/>
                <circle cx="53" cy="47" r="2" fill="white"/>
                <path d="M 45 54 Q 50 58 55 54" stroke="white" stroke-width="2" fill="none"/>
                <!-- è¿æ¥çº¿ -->
                <line x1="35" y1="40" x2="42" y2="47" stroke="#667eea" stroke-width="2" opacity="0.6"/>
                <line x1="65" y1="40" x2="58" y2="47" stroke="#667eea" stroke-width="2" opacity="0.6"/>
            </svg>
            <div style="font-weight: bold; font-size: 1.4rem;">PaperPal</div>
            <div style="font-size: 0.9rem; opacity: 0.9;">AIè®ºæ–‡åŠ©æ‰‹</div>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("### âš™ï¸ APIé…ç½®")
        
        # APIé€‰æ‹©
        api_choice = st.selectbox(
            "é€‰æ‹©APIæœåŠ¡å•†",
            ["doubao", "openai", "qwen"],
            format_func=lambda x: {
                "doubao": "ğŸš€ ç«å±±å¼•æ“è±†åŒ…",
                "openai": "ğŸ¤– OpenAI GPT",
                "qwen": "ğŸ”¥ é˜¿é‡Œäº‘é€šä¹‰åƒé—®"
            }[x]
        )
    
    # ä¸»ç•Œé¢ - æ ‡é¢˜
    st.markdown('<h1 class="main-header">PaperPal - AIè®ºæ–‡åŠ©æ‰‹</h1>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle">ğŸ§  è®©AIå¸®ä½ ç†è§£ä»»ä½•å­¦æœ¯è®ºæ–‡</p>', unsafe_allow_html=True)
    
    # æ£€æŸ¥APIé…ç½®
    api_configured = False
    if api_choice == "doubao":
        if os.getenv("DOUBAO_API_KEY") and os.getenv("DOUBAO_ENDPOINT_ID"):
            api_configured = True
        else:
            st.error("âš ï¸ è¯·é…ç½®ç«å±±å¼•æ“è±†åŒ…APIå¯†é’¥ï¼éœ€è¦DOUBAO_API_KEYå’ŒDOUBAO_ENDPOINT_IDã€‚")
    elif api_choice == "qwen":
        if os.getenv("QWEN_API_KEY"):
            api_configured = True
        else:
            st.error("âš ï¸ è¯·é…ç½®é€šä¹‰åƒé—®APIå¯†é’¥ï¼éœ€è¦QWEN_API_KEYã€‚")
    else:
        if os.getenv("OPENAI_API_KEY"):
            api_configured = True
        else:
            st.error("âš ï¸ è¯·é…ç½®OpenAI APIå¯†é’¥ï¼è¯·åˆ›å»º.envæ–‡ä»¶å¹¶å¡«å…¥OPENAI_API_KEYã€‚")
    
    if not api_configured:
        st.info("ğŸ’¡ è¯·å‚è€ƒenv_example.txtæ–‡ä»¶åˆ›å»º.envé…ç½®æ–‡ä»¶ã€‚")
        return
    
    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    uploaded_file = st.file_uploader(
        "ğŸ”º ä¸Šä¼ PDFè®ºæ–‡",
        type="pdf",
        help="æ”¯æŒä¸Šä¼ å­¦æœ¯è®ºæ–‡PDFæ–‡ä»¶ï¼Œæœ€å¤§10MB"
    )
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        file_details = {
            "æ–‡ä»¶å": uploaded_file.name,
            "æ–‡ä»¶å¤§å°": f"{uploaded_file.size / (1024*1024):.1f} MB",
            "æ–‡ä»¶ç±»å‹": uploaded_file.type
        }
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown(f"""
            <div class="success-box">
                <h4>âœ… PDFæ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼</h4>
                <p><strong>æ–‡ä»¶å</strong>: {file_details["æ–‡ä»¶å"]}</p>
                <p><strong>æ–‡ä»¶å¤§å°</strong>: {file_details["æ–‡ä»¶å¤§å°"]}</p>
                <p><strong>æ–‡ä»¶ç±»å‹</strong>: {file_details["æ–‡ä»¶ç±»å‹"]}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            api_name = {
                "doubao": "ğŸš€ ç«å±±å¼•æ“è±†åŒ…",
                "qwen": "ğŸ”¥ é˜¿é‡Œäº‘é€šä¹‰åƒé—®", 
                "openai": "ğŸ¤– OpenAI GPT"
            }.get(api_choice, "Unknown")
            
            st.markdown(f"""
            <div class="info-box">
                <h4>ğŸ”§ APIé…ç½®</h4>
                <p><strong>å½“å‰ä½¿ç”¨</strong>: {api_name}</p>
                <p><strong>çŠ¶æ€</strong>: âœ… å·²è¿æ¥</p>
            </div>
            """, unsafe_allow_html=True)
        
        # å¤„ç†PDFå¹¶åˆ›å»ºé—®ç­”é“¾
        with st.spinner("ğŸ”„ AIæ­£åœ¨åˆ†æè®ºæ–‡å†…å®¹..."):
            qa_chain = load_pdf_and_create_qa_chain(uploaded_file, api_choice)
        
        if qa_chain:
            st.markdown("""
            <div class="success-box">
                <h3>ğŸ‰ è®ºæ–‡åˆ†æå®Œæˆï¼</h3>
                <p>âœ¨ AIå·²ç»ç†è§£äº†è®ºæ–‡å†…å®¹ï¼Œç°åœ¨å¯ä»¥å¼€å§‹æ™ºèƒ½é—®ç­”äº†</p>
                <p>ğŸ’¡ è¯•è¯•é—®ä¸€äº›å…³äºè®ºæ–‡çš„é—®é¢˜å§ï¼</p>
            </div>
            """, unsafe_allow_html=True)
            
            # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
            if "messages" not in st.session_state:
                st.session_state.messages = []
            
            # æ˜¾ç¤ºèŠå¤©å†å²
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])
            
            # èŠå¤©è¾“å…¥
            if prompt := st.chat_input("ğŸ¤” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)
                
                # ç”ŸæˆAIå›ç­”
                with st.chat_message("assistant"):
                    with st.spinner("ğŸ¤– AIæ­£åœ¨æ€è€ƒ..."):
                        try:
                            if api_choice == "doubao":
                                # è±†åŒ…API
                                response = qa_chain(prompt)
                            else:
                                # OpenAI API
                                response = qa_chain.run(prompt)
                            
                            st.markdown(response)
                            st.session_state.messages.append({"role": "assistant", "content": response})
                        
                        except Exception as e:
                            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}"
                            st.error(error_msg)
                            st.session_state.messages.append({"role": "assistant", "content": error_msg})
            
            # æ¸…é™¤å¯¹è¯æŒ‰é’®
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯å†å²"):
                st.session_state.messages = []
                st.rerun()
    
    else:
        # æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶æ—¶çš„ç•Œé¢
        st.markdown("""
        <div style="text-align: center; padding: 30px 25px; background: rgba(102, 126, 234, 0.1); border: 1px solid rgba(102, 126, 234, 0.2); border-radius: 12px; margin: 20px 0;">
            <div style="display: flex; align-items: center; justify-content: center; margin-bottom: 0.5rem;">
                <svg width="35" height="35" viewBox="0 0 100 100" style="margin-right: 10px;">
                    <!-- ä¹¦æœ¬å›¾æ ‡ -->
                    <rect x="20" y="25" width="60" height="50" rx="5" fill="#667eea" stroke="#667eea" stroke-width="1" opacity="0.8"/>
                    <rect x="25" y="30" width="50" height="40" rx="3" fill="rgba(255,255,255,0.9)"/>
                    <!-- AIå¤§è„‘å›¾æ ‡ -->
                    <circle cx="50" cy="50" r="12" fill="#667eea" opacity="0.7"/>
                    <circle cx="47" cy="47" r="2" fill="white"/>
                    <circle cx="53" cy="47" r="2" fill="white"/>
                    <path d="M 45 54 Q 50 58 55 54" stroke="white" stroke-width="2" fill="none"/>
                    <!-- è¿æ¥çº¿ -->
                    <line x1="35" y1="40" x2="42" y2="47" stroke="#667eea" stroke-width="2" opacity="0.6"/>
                    <line x1="65" y1="40" x2="58" y2="47" stroke="#667eea" stroke-width="2" opacity="0.6"/>
                </svg>
                <h2 style="font-size: 1.8rem; margin: 0; color: #667eea;">æ¬¢è¿ä½¿ç”¨PaperPal</h2>
            </div>
            <p style="font-size: 1rem; margin: 10px 0; color: #666;">ä¸Šä¼ PDFè®ºæ–‡ï¼Œå¼€å§‹æ™ºèƒ½å¯¹è¯</p>
        </div>
        """, unsafe_allow_html=True)
        
        # ç®€åŒ–çš„ç¤ºä¾‹é—®é¢˜
        st.markdown("""
        <h3 style="color: #667eea; margin: 30px 0 20px 0; font-size: 1.3rem;">
            <svg width="20" height="20" viewBox="0 0 100 100" style="margin-right: 8px; vertical-align: middle;">
                <circle cx="50" cy="50" r="12" fill="#667eea" opacity="0.7"/>
                <circle cx="47" cy="47" r="2" fill="white"/>
                <circle cx="53" cy="47" r="2" fill="white"/>
                <path d="M 45 54 Q 50 58 55 54" stroke="white" stroke-width="2" fill="none"/>
            </svg>
            è¯•è¯•è¿™äº›é—®é¢˜
        </h3>
        """, unsafe_allow_html=True)
        
        examples = [
            "ğŸ“ è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦è§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
            "ğŸ” å®éªŒç”¨äº†ä»€ä¹ˆæ•°æ®é›†ï¼Ÿ", 
            "ğŸ’¡ è¿™ä¸ªæ–¹æ³•æœ‰ä»€ä¹ˆåˆ›æ–°ç‚¹ï¼Ÿ",
            "ğŸ¯ æœ‰å“ªäº›å±€é™æ€§ï¼Ÿ"
        ]
        
        for example in examples:
            st.markdown(f"""
            <div style="padding: 12px 16px; background: rgba(102, 126, 234, 0.06); border: 1px solid rgba(102, 126, 234, 0.15); border-radius: 8px; margin: 8px 0;">
                <p style="margin: 0; color: #555; font-size: 0.95rem;">{example}</p>
            </div>
            """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
